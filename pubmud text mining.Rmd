---
title: "pubmed text mining"
author: "arrowif"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## about pubmed.mineR
65 functions including text mining and data mining
```{r cars}
# install.packages('pubmed.mineR')
library(pubmed.mineR)
#ls("package:pubmed.mineR")
```

## Text Mining

from PubMed download the Abstrast(test) resultï¼Œcreat pubmed_result.txt file

using readabs() read the result file

generate the pubmed_abstracts data is a kind of S4 object, including: Journal,abstract, PMID

```{r pressure, echo=FALSE}
library(pubmed.mineR)
pubmed_abstracts <- readabs("pubmed_result.txt")
class(pubmed_abstracts)
# [1] "Abstracts"
printabs(pubmed_abstracts)  ## show the start and end part of the file
```
## extract pmid from abstracts data
```{r}
pmid <- pubmed_abstracts@PMID
head(pmid)
class(pmid)
# [1] "numeric"
```

## extract  from  abstracts data,  and get sentences token
```{r}
abstractst <- pubmed_abstracts@Abstract

#head(abstractst)

SentenceToken(abstractst[2])
```

word frequence in the file

```{r}
library(RISmed)
library(dplyr)
library(ggplot2)
library(tidytext)
library(wordcloud)

result <- EUtilsSummary("Gallic acid AND hepg2 ", 
                         type = "esearch", 
                         db = "pubmed",
                         #datetype = "pdat",
                         retmax = 10000,
                         mindate = 1970, 
                         maxdate = 2020)
fetch <- EUtilsGet(result, type = "efetch", db = "pubmed")
abstracts <- data.frame(title = fetch@ArticleTitle,
                        abstract = fetch@AbstractText,
                        journal = fetch@Title,
                        DOI = fetch@PMID,
                        year = fetch@YearPubmed)
abstracts <- abstracts %>% mutate(abstract = as.character(abstract))
abstracts %>%
  group_by(year) %>%
  count() %>%
  filter(year > 1969) %>%
  ggplot(aes(year, n)) +
  geom_point() +
  geom_line() +
  labs(title = "Pubmed articles with search terms Gallic acid hepg2 \n1970-2020", hjust = 0.5,
       y = "Articles")

```




```{r}
cloud <- abstracts %>%
  unnest_tokens(word, abstract) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE)
cloud %>%
  with(wordcloud(word, n, min.freq = 15, max.words = 500, colors = brewer.pal(8, "Dark2")), scale = c(8,.3), per.rot = 0.4)
```

